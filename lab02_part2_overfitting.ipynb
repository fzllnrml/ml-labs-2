{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFmOh482SyEF"
      },
      "source": [
        "## Lab 2\n",
        "### Part 2: Dealing with overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjzAuO3oSvsI"
      },
      "source": [
        "Today we work with [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) (*hint: it is available in `torchvision`*).\n",
        "\n",
        "Your goal for today:\n",
        "1. Train a FC (fully-connected) network that achieves >= 0.885 test accuracy.\n",
        "2. Cause considerable overfitting by modifying the network (e.g. increasing the number of network parameters and/or layers) and demonstrate in in the appropriate way (e.g. plot loss and accurasy on train and validation set w.r.t. network complexity).\n",
        "3. Try to deal with overfitting (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results.\n",
        "\n",
        "__Please, write a small report describing your ideas, tries and achieved results in the end of this file.__\n",
        "\n",
        "*Note*: Tasks 2 and 3 are interrelated, in task 3 your goal is to make the network from task 2 less prone to overfitting. Task 1 is independent from 2 and 3.\n",
        "\n",
        "*Note 2*: We recomment to use Google Colab or other machine with GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KBld6VOSwhW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchsummary\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdLOG0XqS_g5",
        "outputId": "b32637a6-c729-4fc4-da3d-f3be034813ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory fmnist already exists!\n"
          ]
        }
      ],
      "source": [
        "# Technical function\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(root_path):\n",
        "        os.mkdir(root_path)\n",
        "        print('Directory', path, 'is created!')\n",
        "    else:\n",
        "        print('Directory', path, 'already exists!')\n",
        "\n",
        "root_path = 'fmnist'\n",
        "mkdir(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt6LE7XaTDT9"
      },
      "outputs": [],
      "source": [
        "download = True\n",
        "train_transform = transforms.ToTensor()\n",
        "test_transform = transforms.ToTensor()\n",
        "transforms.Compose((transforms.ToTensor()))\n",
        "\n",
        "\n",
        "fmnist_dataset_train = torchvision.datasets.FashionMNIST(root_path,\n",
        "                                                        train=True,\n",
        "                                                        transform=train_transform,\n",
        "                                                        target_transform=None,\n",
        "                                                        download=download)\n",
        "fmnist_dataset_test = torchvision.datasets.FashionMNIST(root_path,\n",
        "                                                       train=False,\n",
        "                                                       transform=test_transform,\n",
        "                                                       target_transform=None,\n",
        "                                                       download=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71YP0SPwTIxD"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(fmnist_dataset_train,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(fmnist_dataset_test,\n",
        "                                          batch_size=256,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_YFmF7NTWrQ",
        "outputId": "9c81d938-8fdb-4ff2-b1a3-42e5c31c8c83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(fmnist_dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHca15bOTY4B",
        "outputId": "cb114605-192c-424e-c391-1046de99d397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128])\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "for img, label in train_loader:\n",
        "    print(img.shape)\n",
        "#     print(img)\n",
        "    print(label.shape)\n",
        "    print(label.size(0))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6OOOffHTfX5"
      },
      "source": [
        "### Task 1\n",
        "Train a network that achieves $\\geq 0.885$ test accuracy. It's fine to use only Linear (`nn.Linear`) layers and activations/dropout/batchnorm. Convolutional layers might be a great use, but we will meet them a bit later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftpkTjxlTcFx"
      },
      "outputs": [],
      "source": [
        "class TinyNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
        "            # Your network structure comes here\n",
        "            nn.Linear(input_shape, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5_0v649ML2Z",
        "outputId": "3ce6e26b-a1d5-4e02-b355-ecb319ffab86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                  [-1, 512]         401,920\n",
            "              ReLU-3                  [-1, 512]               0\n",
            "            Linear-4                  [-1, 128]          65,664\n",
            "              ReLU-5                  [-1, 128]               0\n",
            "            Linear-6                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 1.79\n",
            "Estimated Total Size (MB): 1.81\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(TinyNeuralNetwork().to(device), (28*28,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "544PGKEnjPr5"
      },
      "source": [
        "Your experiments come here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3POFj90Ti-6",
        "outputId": "5e93ecd1-0629-4101-dba4-0193a2fc2037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1, Accuracy 0.8442\n",
            "Эпоха 2, Accuracy 0.859\n",
            "Эпоха 3, Accuracy 0.8714\n",
            "Эпоха 4, Accuracy 0.8724\n",
            "Эпоха 5, Accuracy 0.8759\n",
            "Эпоха 6, Accuracy 0.8843\n",
            "Эпоха 7, Accuracy 0.8809\n",
            "Эпоха 8, Accuracy 0.8857\n",
            "Эпоха 9, Accuracy 0.8825\n",
            "Эпоха 10, Accuracy 0.8873\n",
            "Эпоха 11, Accuracy 0.884\n",
            "Эпоха 12, Accuracy 0.8885\n",
            "Эпоха 13, Accuracy 0.8857\n",
            "Эпоха 14, Accuracy 0.8886\n",
            "Эпоха 15, Accuracy 0.8949\n"
          ]
        }
      ],
      "source": [
        "model = TinyNeuralNetwork().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        logits = model(X_batch)\n",
        "        loss = loss_func(logits, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val in test_loader:\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "            logits = model(X_val)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total_samples += y_val.size(0)\n",
        "            total_correct += (predicted == y_val).sum().item()\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Эпоха {epoch+1}, Accuracy {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ISqkjmCPB1"
      },
      "source": [
        "### Task 2: Overfit it.\n",
        "Build a network that will overfit to this dataset. Demonstrate the overfitting in the appropriate way (e.g. plot loss and accurasy on train and test set w.r.t. network complexity).\n",
        "\n",
        "*Note:* you also might decrease the size of `train` dataset to enforce the overfitting and speed up the computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H12uAWiGBwJx"
      },
      "outputs": [],
      "source": [
        "class OverfittingNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
        "            # Your network structure comes here\n",
        "            nn.Linear(input_shape, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgXAKCpvCwqH",
        "outputId": "08e0ec79-9a65-4446-ca99-66d690fae408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                 [-1, 2048]       1,607,680\n",
            "              ReLU-3                 [-1, 2048]               0\n",
            "            Linear-4                 [-1, 1024]       2,098,176\n",
            "              ReLU-5                 [-1, 1024]               0\n",
            "            Linear-6                  [-1, 512]         524,800\n",
            "              ReLU-7                  [-1, 512]               0\n",
            "            Linear-8                  [-1, 128]          65,664\n",
            "              ReLU-9                  [-1, 128]               0\n",
            "           Linear-10                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 4,297,610\n",
            "Trainable params: 4,297,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 16.39\n",
            "Estimated Total Size (MB): 16.46\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(OverfittingNeuralNetwork().to(device), (28*28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgLZhEB1ML2Z",
        "outputId": "9f047827-1651-4f3d-a184-965ad3726c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1, Accuracy 0.831\n",
            "Эпоха 2, Accuracy 0.8622\n",
            "Эпоха 3, Accuracy 0.8722\n",
            "Эпоха 4, Accuracy 0.8767\n",
            "Эпоха 5, Accuracy 0.8797\n",
            "Эпоха 6, Accuracy 0.8739\n",
            "Эпоха 7, Accuracy 0.8869\n",
            "Эпоха 8, Accuracy 0.8839\n",
            "Эпоха 9, Accuracy 0.8893\n",
            "Эпоха 10, Accuracy 0.8883\n",
            "Эпоха 11, Accuracy 0.8907\n",
            "Эпоха 12, Accuracy 0.8835\n",
            "Эпоха 13, Accuracy 0.8898\n",
            "Эпоха 14, Accuracy 0.8901\n",
            "Эпоха 15, Accuracy 0.8877\n",
            "Эпоха 16, Accuracy 0.8866\n",
            "Эпоха 17, Accuracy 0.8936\n",
            "Эпоха 18, Accuracy 0.8923\n",
            "Эпоха 19, Accuracy 0.8942\n",
            "Эпоха 20, Accuracy 0.8923\n",
            "Эпоха 21, Accuracy 0.8957\n",
            "Эпоха 22, Accuracy 0.8945\n",
            "Эпоха 23, Accuracy 0.8912\n",
            "Эпоха 24, Accuracy 0.8906\n",
            "Эпоха 25, Accuracy 0.9006\n",
            "Эпоха 26, Accuracy 0.8965\n",
            "Эпоха 27, Accuracy 0.8962\n",
            "Эпоха 28, Accuracy 0.8989\n",
            "Эпоха 29, Accuracy 0.896\n",
            "Эпоха 30, Accuracy 0.9007\n"
          ]
        }
      ],
      "source": [
        "model = OverfittingNeuralNetwork().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        logits = model(X_batch)\n",
        "        loss = loss_func(logits, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val in test_loader:\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "            logits = model(X_val)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total_samples += y_val.size(0)\n",
        "            total_correct += (predicted == y_val).sum().item()\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Эпоха {epoch+1}, Accuracy {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOv2PwI8ML2Z"
      },
      "source": [
        "### Task 3: Fix it.\n",
        "Fix the overfitted network from the previous step (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxpwln8yML2Z"
      },
      "outputs": [],
      "source": [
        "class FixedNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
        "            # Your network structure comes here\n",
        "            nn.Linear(input_shape, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTPMlgEeML2Z",
        "outputId": "b7eec815-0260-4361-a267-b7e849c18403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                 [-1, 2048]       1,607,680\n",
            "              ReLU-3                 [-1, 2048]               0\n",
            "       BatchNorm1d-4                 [-1, 2048]           4,096\n",
            "           Dropout-5                 [-1, 2048]               0\n",
            "            Linear-6                 [-1, 1024]       2,098,176\n",
            "              ReLU-7                 [-1, 1024]               0\n",
            "       BatchNorm1d-8                 [-1, 1024]           2,048\n",
            "           Dropout-9                 [-1, 1024]               0\n",
            "           Linear-10                  [-1, 512]         524,800\n",
            "             ReLU-11                  [-1, 512]               0\n",
            "      BatchNorm1d-12                  [-1, 512]           1,024\n",
            "          Dropout-13                  [-1, 512]               0\n",
            "           Linear-14                  [-1, 128]          65,664\n",
            "             ReLU-15                  [-1, 128]               0\n",
            "      BatchNorm1d-16                  [-1, 128]             256\n",
            "          Dropout-17                  [-1, 128]               0\n",
            "           Linear-18                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 4,305,034\n",
            "Trainable params: 4,305,034\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.12\n",
            "Params size (MB): 16.42\n",
            "Estimated Total Size (MB): 16.54\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(FixedNeuralNetwork().to(device), (28*28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZisNe3HML2Z",
        "outputId": "e588243e-b9fa-43ca-9eb2-853d8e432cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1, Accuracy 0.852\n",
            "Эпоха 2, Accuracy 0.8602\n",
            "Эпоха 3, Accuracy 0.8591\n",
            "Эпоха 4, Accuracy 0.8656\n",
            "Эпоха 5, Accuracy 0.8624\n",
            "Эпоха 6, Accuracy 0.867\n",
            "Эпоха 7, Accuracy 0.8668\n",
            "Эпоха 8, Accuracy 0.8792\n",
            "Эпоха 9, Accuracy 0.8737\n",
            "Эпоха 10, Accuracy 0.8821\n",
            "Эпоха 11, Accuracy 0.879\n",
            "Эпоха 12, Accuracy 0.8825\n",
            "Эпоха 13, Accuracy 0.884\n",
            "Эпоха 14, Accuracy 0.8845\n",
            "Эпоха 15, Accuracy 0.878\n",
            "Эпоха 16, Accuracy 0.8876\n",
            "Эпоха 17, Accuracy 0.8832\n",
            "Эпоха 18, Accuracy 0.8832\n",
            "Эпоха 19, Accuracy 0.8893\n",
            "Эпоха 20, Accuracy 0.8851\n",
            "Эпоха 21, Accuracy 0.8865\n",
            "Эпоха 22, Accuracy 0.8838\n",
            "Эпоха 23, Accuracy 0.8907\n",
            "Эпоха 24, Accuracy 0.8891\n",
            "Эпоха 25, Accuracy 0.8875\n",
            "Эпоха 26, Accuracy 0.89\n",
            "Эпоха 27, Accuracy 0.887\n",
            "Эпоха 28, Accuracy 0.8901\n",
            "Эпоха 29, Accuracy 0.8878\n",
            "Эпоха 30, Accuracy 0.89\n"
          ]
        }
      ],
      "source": [
        "model = FixedNeuralNetwork().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        logits = model(X_batch)\n",
        "        loss = loss_func(logits, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val in test_loader:\n",
        "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "            logits = model(X_val)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total_samples += y_val.size(0)\n",
        "            total_correct += (predicted == y_val).sum().item()\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Эпоха {epoch+1}, Accuracy {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMui_uLJ7G0d"
      },
      "source": [
        "### Conclusions:\n",
        "_Write down small report with your conclusions and your ideas._"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}